
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://optimi.benjaminwarner.dev/kahan_summation/">
      
      
      
        <link rel="next" href="../triton/">
      
      
      <link rel="icon" href="../images/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.16">
    
    
      
        <title>Low Precision Training with Kahan Summation - optimī</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.7e37652d.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CJetbrains+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"Jetbrains Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../css/extra.css">
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="swiss" data-md-color-primary="swiss" data-md-color-accent="swiss">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#low-precision-training-with-kahan-summation" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      <!-- Determine classes -->


  


<!-- Header -->
<header class="md-header md-header--shadow" data-md-component="header">
  <nav
    class="md-header__inner md-grid"
    aria-label="Header"
  >

    <!-- Link to home -->
    <a
      href=".."
      title="optimī"
      aria-label="optimī"
    >
      <span class="custom-title">
        optimī
      </span>
    </a>

    <!-- Button to open drawer -->
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>

    <!-- Header title -->
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis"></span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Low Precision Training with Kahan Summation
            
          </span>
        </div>
      </div>
    </div>

    <!-- Color palette toggle -->
    
      
    

    <!-- Site language selector -->
    

    <!-- Button to open search modal -->
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>

      <!-- Search interface -->
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    

    <!-- Repository information -->
    
      <div class="md-header__source">
        <a href="https://github.com/warner-benjamin/optimi" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    warner-benjamin/optimi
  </div>
</a>
      </div>
    
  </nav>

  <!-- Navigation tabs (sticky) -->
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<!-- Determine classes -->




<!-- Navigation -->
<nav
  class="md-nav md-nav--primary"
  aria-label="Navigation"
  data-md-level="0"
>

  <!-- Site title -->
  <label class="md-nav__title" for="__drawer">
    <a
      href=".."
      title="optimī"
      class="md-nav__button md-logo"
      aria-label="optimī"
      data-md-component="logo"
    >
      optimī
    </a>
    optimī
  </label>

  <!-- Repository information -->
  
    <div class="md-nav__source">
      <a href="https://github.com/warner-benjamin/optimi" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    warner-benjamin/optimi
  </div>
</a>
    </div>
  

  <!-- Navigation list -->
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Low Precision Training
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Low Precision Training
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#mixed-precision" class="md-nav__link">
    <span class="md-ellipsis">
      Mixed Precision
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kahan-summation" class="md-nav__link">
    <span class="md-ellipsis">
      Kahan Summation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#memory-savings" class="md-nav__link">
    <span class="md-ellipsis">
      Memory Savings
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-speedup" class="md-nav__link">
    <span class="md-ellipsis">
      Training Speedup
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#example" class="md-nav__link">
    <span class="md-ellipsis">
      Example
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#explanation" class="md-nav__link">
    <span class="md-ellipsis">
      Explanation
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../triton/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Triton Optimizers
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../fully_decoupled_weight_decay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Fully Decoupled Weight Decay
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../gradient_release/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Gradient Release
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimizer_accumulation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Optimizer Accumulation
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../foreach/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ForEach Optimizers
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../which_optimizer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Which Optimizer?
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Optimizers
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            Optimizers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimizers/adam/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Adam
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimizers/adamw/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AdamW
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimizers/adan/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Adan
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimizers/lion/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lion
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimizers/radam/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RAdam
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimizers/ranger/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ranger
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimizers/sgd/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    SGD
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimizers/stableadamw/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    StableAdamW
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../utils/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Utilities
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#mixed-precision" class="md-nav__link">
    <span class="md-ellipsis">
      Mixed Precision
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kahan-summation" class="md-nav__link">
    <span class="md-ellipsis">
      Kahan Summation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#memory-savings" class="md-nav__link">
    <span class="md-ellipsis">
      Memory Savings
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-speedup" class="md-nav__link">
    <span class="md-ellipsis">
      Training Speedup
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#example" class="md-nav__link">
    <span class="md-ellipsis">
      Example
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#explanation" class="md-nav__link">
    <span class="md-ellipsis">
      Explanation
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="low-precision-training-with-kahan-summation">Low Precision Training with Kahan Summation<a class="headerlink" href="#low-precision-training-with-kahan-summation" title="Permanent link">¶</a></h1>
<p>While training models in low precision (Float16 or BFloat16) usually differs from training in full precision (Float32) or <a href="https://pytorch.org/blog/what-every-user-should-know-about-mixed-precision-training-in-pytorch">mixed precision</a>, optimi optimizers can match the performance of mixed precision when training in pure BFloat16 by using Kahan summation<sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup>.</p>
<p><img alt="" src="https://ghp-cdn.benjaminwarner.dev/optimi/kahan_pretrain.png"></p>
<p>Training in low precision <a href="#memory-savings">reduces non-activation memory usage up to ~46 percent</a> and can increase <a href="#training-speedup">training speed up to ~30 percent</a> relative to mixed precision training.</p>
<p>Using Kahan summation for accurate BFloat16 training is as simple as replacing a PyTorch optimizer with its optimi equivalent and casting the model to BFloat16 instead of using mixed precision.</p>
<div class="admonition tip">
<p class="admonition-title">Tip: Keep a Few Layers in Float32</p>
<p>When training in BFloat16, keep rotary buffers, rotary calculations, and token embedding layers in Float32, as these benefit from full precision. This results in a small memory increase and speed decrease, but can help guarantee equivalent results with mixed precision training.</p>
</div>
<p>By default, optimi optimizers will automatically use Kahan summation for any layers training in low precision. Set <code>kahan_sum=False</code> to disable.</p>
<h2 id="mixed-precision">Mixed Precision<a class="headerlink" href="#mixed-precision" title="Permanent link">¶</a></h2>
<p>While implementations details can differ, mixed precision works by running a forward pass in low precision, automatically switching to full precision per layer as needed, and then accumulating gradients during the backward pass in Float32. The optimizer step runs in full precision.</p>
<p>The hybrid precision setup of mixed precision enables the faster operations and lower memory usage of low precision while keeping the convergence of full precision.</p>
<h2 id="kahan-summation">Kahan Summation<a class="headerlink" href="#kahan-summation" title="Permanent link">¶</a></h2>
<p><a href="https://en.wikipedia.org/wiki/Kahan_summation_algorithm">Kahan summation</a><sup id="fnref:2"><a class="footnote-ref" href="#fn:2">2</a></sup> is a technique to reduce the numerical error of adding multiple low precision numbers by accumulating errors in a separate compensation buffer. The addition of the compensation buffer increases the effective summation precision by the precision of the compensation buffer.</p>
<p>Using Kahan summation to improve low precision model training was first introduced by Zamirai et al in <a href="https://arxiv.org/abs/2010.06192"><em>Revisiting BFloat16 Training</em></a>. Zamirai et al discovered the primary source of numerical error from low precision training is during the optimizer’s model weight update step. They add Kahan summation to the SGD &amp; AdamW weight update steps to reduce the update’s numerical inaccuracy, increasing low precision training to the equivalent of full precision training across tested models.</p>
<details class="note">
<summary>Note: Implementation Inspired by TorchDistX</summary>
<p>optimi’s Kahan summation implementation was directly inspired by <a href="https://github.com/pytorch/torchdistx">TorchDistX’s</a> <code>AnyPrecisionAdamW</code> optimizer.</p>
</details>
<p>For more details, see the <a href="#algorithm">algorithm</a> and <a href="#explanation">explanation</a> sections.</p>
<h2 id="memory-savings">Memory Savings<a class="headerlink" href="#memory-savings" title="Permanent link">¶</a></h2>
<p>Training in pure BFloat16 with Kahan summation can reduce non-activation training memory usage up to 37 to 45 percent when using an Adam optimizer, as Table 1 shows below.</p>
<table id="_table-1">
<caption style="caption-side:top">Table 1: Adam Per Parameter Memory Usage, Excluding Activations</caption><thead>
<tr>
<th style="text-align: left;">Buffer</th>
<th style="text-align: center;">Mixed Precision</th>
<th style="text-align: center;">BFloat16 + Kahan Sum</th>
<th style="text-align: center;">BFloat16</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">BF16 Model Weights (if used)</td>
<td style="text-align: center;">2 bytes</td>
<td style="text-align: center;">2 bytes</td>
<td style="text-align: center;">2 bytes</td>
</tr>
<tr>
<td style="text-align: left;">FP32 Model Weights</td>
<td style="text-align: center;">4 bytes</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">Gradients</td>
<td style="text-align: center;">4 bytes</td>
<td style="text-align: center;">2 bytes</td>
<td style="text-align: center;">2 bytes</td>
</tr>
<tr>
<td style="text-align: left;">Distributed Buffer (optional)</td>
<td style="text-align: center;">4 bytes</td>
<td style="text-align: center;">2 bytes</td>
<td style="text-align: center;">2 bytes</td>
</tr>
<tr>
<td style="text-align: left;">Momentum</td>
<td style="text-align: center;">4 bytes</td>
<td style="text-align: center;">2 bytes</td>
<td style="text-align: center;">2 bytes</td>
</tr>
<tr>
<td style="text-align: left;">Variance</td>
<td style="text-align: center;">4 bytes</td>
<td style="text-align: center;">2 bytes</td>
<td style="text-align: center;">2 bytes</td>
</tr>
<tr>
<td style="text-align: left;">Kahan Compensation</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">2 bytes</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Total</strong></td>
<td style="text-align: center;">16-22 bytes</td>
<td style="text-align: center;">10-12 bytes</td>
<td style="text-align: center;">8-10 bytes</td>
</tr>
</tbody>
</table>
<p>Calculating the total memory savings depends on <a href="https://blog.eleuther.ai/transformer-math/#activations-and-batch-size">activations and batch size</a>, mixed precision implementation details, and the optimizer used, to name a few variables.</p>
<p>optimi reduces potential extra memory overhead of Kahan summation by reusing the gradient buffer for temporary variables.</p>
<h2 id="training-speedup">Training Speedup<a class="headerlink" href="#training-speedup" title="Permanent link">¶</a></h2>
<p>Training in BFloat16 instead of mixed precision results in up to a ~10% speedup on a single GPU, up to a ~20% speedup with two GPUs, and up to a ~30% speedup with multiple GPUs<sup id="fnref:3"><a class="footnote-ref" href="#fn:3">3</a></sup>.</p>
<h2 id="example">Example<a class="headerlink" href="#example" title="Permanent link">¶</a></h2>
<p>Using Kahan summation with an optimi optimizer only requires a casting a model and optionally input into low precision (BFloat16 or Float16). Since Kahan summation is applied layer by layer, it works for models with standard and low precision weights.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">optimi</span><span class="w"> </span><span class="kn">import</span> <span class="n">AdamW</span>

<span class="c1"># create or cast some model layers in low precision (bfloat16)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">)</span>

<span class="c1"># initialize any optmi optimizer with low precsion parameters</span>
<span class="c1"># Kahan summation is enabled since some model layers are bfloat16</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<span class="c1"># forward and backward, casting input to bfloat16 if needed</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">))</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="c1"># optimizer step automatically uses Kahan summation for low precision layers</span>
<span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</code></pre></div>
<p>To disable Kahan Summation pass <code>kahan_summation=False</code> on optimizer initialization.</p>
<h2 id="algorithm">Algorithm<a class="headerlink" href="#algorithm" title="Permanent link">¶</a></h2>
<p>SGD with Kahan summation.</p>
<div class="arithmatex">\[
\begin{aligned}
    &amp;\rule{90mm}{0.4pt}\\
    &amp;\hspace{2mm} \textcolor{#009ddb}{\textbf{SGD}} \: \textcolor{#9a3fe4}{\text{with Kahan summation}}\\
    &amp;\hspace{5mm} \text{inputs} : \bm{\theta}_0 \: \text{(params)}; \: f(\bm{\theta}) \text{(objective)};\\
    &amp;\hspace{17.25mm} \gamma_t \:\text{(learning rate at } t \text{)}; \: \lambda \: \text{(weight decay)}\\
    &amp;\hspace{5mm} \text{initialize} : \textcolor{#9a3fe4}{\bm{k}_{0} \leftarrow \bm{0}}\\[-0.5em]
    &amp;\rule{90mm}{0.4pt}\\
    &amp;\hspace{5mm} \textbf{for} \: t=1 \: \textbf{to} \: \ldots \: \textbf{do}\text{:}\\
        &amp;\hspace{10mm} \bm{g}_t \leftarrow \nabla_{\theta} f_t(\bm{\theta}_{t-1}) - \lambda\bm{\theta}_{t-1}\\[0.5em]
        &amp;\hspace{10mm} \textcolor{#009ddb}{\bm{\theta}_t \leftarrow \bm{\theta}_{t-1} - \gamma_t\bm{g}_t}\\[0.3em]
        &amp;\hspace{10mm} \textcolor{#9a3fe4}{\bm{u}_t \leftarrow \bm{k}_{t-1} - \gamma_t\bm{g}_t}\\
        &amp;\hspace{10mm} \textcolor{#9a3fe4}{\bm{\theta}_t \leftarrow \bm{\theta}_{t-1} + \bm{u}_t}\\
        &amp;\hspace{10mm} \textcolor{#9a3fe4}{\bm{k}_t \leftarrow \bm{u}_t + (\bm{\theta}_{t-1} - \bm{\theta}_t)}\\[-0.5em]
    &amp;\rule{90mm}{0.4pt}\\
\end{aligned}
\]</div>
<p>This shows the optimi implementation of Kahan summation optimizers, which is equivalent to the <em>Revisiting BFloat16 Training</em> formulation.</p>
<h2 id="explanation">Explanation<a class="headerlink" href="#explanation" title="Permanent link">¶</a></h2>
<p>optimi optimizers with Kahan summation modify the base optimizers by introducing a compensation buffer <span class="arithmatex">\(k\)</span> to mitigate numerical errors from training in low precision.</p>
<p>Using SGD as an example, the SGD parameter update is straightforward: <span class="arithmatex">\(\textcolor{#009ddb}{\bm{\theta}_t ← \bm{\theta}_{t-1} - \gamma_t\bm{g}_t}\)</span>. Where <span class="arithmatex">\(\theta\)</span> is the model parameters at steps <span class="arithmatex">\(t-1\)</span> and <span class="arithmatex">\(t\)</span>, and <span class="arithmatex">\(\gamma_t\)</span> and <span class="arithmatex">\(g_t\)</span> are the learning rate and gradient at step <span class="arithmatex">\(t\)</span>, respectively.</p>
<p>SGD with Kahan summation expands the single update model parameter step to three steps:</p>
<ol>
<li><span class="arithmatex">\(\textcolor{#9a3fe4}{\bm{u}_t ← \bm{k}_{t-1} - \gamma_t\bm{g}_t}\)</span>: First, an intermediate update <span class="arithmatex">\(u_t\)</span> is computed from the prior compensation buffer <span class="arithmatex">\(k_{t-1}\)</span>. This allows the current parameter update to account for any precision errors in last parameter update.</li>
<li><span class="arithmatex">\(\textcolor{#9a3fe4}{\bm{\theta}_t ← \bm{\theta}_{t-1} + \bm{u}_t}\)</span>: The parameter update uses the error compensated update <span class="arithmatex">\(u_t\)</span> instead of directly subtracting <span class="arithmatex">\(\gamma_t g_t\)</span>.</li>
<li><span class="arithmatex">\(\textcolor{#9a3fe4}{\bm{k}_t ← \bm{u}_t + (\bm{\theta}_{t-1} - \bm{\theta}_t)}\)</span>: Finally, the compensation buffer is updated to stores the difference between the intended update (<span class="arithmatex">\(u_t\)</span>) and the actual change in the parameters <span class="arithmatex">\((\theta_{t-1} - \theta_t)\)</span>, capturing any errors from operating in low precision numerical types.</li>
</ol>
<p>These Kahan summation steps allow optimi optimizers to nearly reach or match the performance of mixed precision when training in low precision.</p>
<div class="footnote">
<hr>
<ol>
<li id="fn:1">
<p>Plot shows a simplified modded-nanogpt 160M model, trained on 1B FineWeb-Edu tokens, with RoPE and token embedding layers in Float32 and all other layers in BFloat16. <a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
<li id="fn:2">
<p>Also known as Kahan–Babuška summation or compensated summation. <a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text">↩</a></p>
</li>
<li id="fn:3">
<p>Pure BFloat16 training can increase distributed training speed more then single GPU due to the halved bandwidth cost. Observed results may differ based on GPU connectivity and effectiveness of computation-communication overlap. Maximum observed speed increase was on consumer GPUs. <a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text">↩</a></p>
</li>
</ol>
</div>







  
  






                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024 Benjamin Warner, MIT License
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/warner-benjamin" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://twitter.com/benjamin_warner" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M459.4 151.7c.3 4.5.3 9.1.3 13.6 0 138.7-105.6 298.6-298.6 298.6-59.5 0-114.7-17.2-161.1-47.1 8.4 1 16.6 1.3 25.3 1.3 49.1 0 94.2-16.6 130.3-44.8-46.1-1-84.8-31.2-98.1-72.8 6.5 1 13 1.6 19.8 1.6 9.4 0 18.8-1.3 27.6-3.6-48.1-9.7-84.1-52-84.1-103v-1.3c14 7.8 30.2 12.7 47.4 13.3-28.3-18.8-46.8-51-46.8-87.4 0-19.5 5.2-37.4 14.3-53C87.4 130.8 165 172.4 252.1 176.9c-1.6-7.8-2.6-15.9-2.6-24C249.5 95.1 296.3 48 354.4 48c30.2 0 57.5 12.7 76.7 33.1 23.7-4.5 46.5-13.3 66.6-25.3-7.8 24.4-24.4 44.8-46.1 57.8 21.1-2.3 41.6-8.1 60.4-16.2-14.3 20.8-32.2 39.3-52.6 54.3"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://threads.net/@_benjaminwarner" target="_blank" rel="noopener" title="threads.net" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M331.5 235.7c2.2.9 4.2 1.9 6.3 2.8 29.2 14.1 50.6 35.2 61.8 61.4 15.7 36.5 17.2 95.8-30.3 143.2-36.2 36.2-80.3 52.5-142.6 53h-.3c-70.2-.5-124.1-24.1-160.4-70.2-32.3-41-48.9-98.1-49.5-169.6v-.5c.5-71.5 17.1-128.6 49.4-169.6 36.3-46.1 90.3-69.7 160.5-70.2h.3c70.3.5 124.9 24 162.3 69.9 18.4 22.7 32 50 40.6 81.7l-40.4 10.8c-7.1-25.8-17.8-47.8-32.2-65.4-29.2-35.8-73-54.2-130.5-54.6-57 .5-100.1 18.8-128.2 54.4C72.1 146.1 58.5 194.3 58 256c.5 61.7 14.1 109.9 40.3 143.3 28 35.6 71.2 53.9 128.2 54.4 51.4-.4 85.4-12.6 113.7-40.9 32.3-32.2 31.7-71.8 21.4-95.9-6.1-14.2-17.1-26-31.9-34.9-3.7 26.9-11.8 48.3-24.7 64.8-17.1 21.8-41.4 33.6-72.7 35.3-23.6 1.3-46.3-4.4-63.9-16-20.8-13.8-33-34.8-34.3-59.3-2.5-48.3 35.7-83 95.2-86.4 21.1-1.2 40.9-.3 59.2 2.8-2.4-14.8-7.3-26.6-14.6-35.2-10-11.7-25.6-17.7-46.2-17.8h-.7c-16.6 0-39 4.6-53.3 26.3l-34.4-23.6c19.2-29.1 50.3-45.1 87.8-45.1h.8c62.6.4 99.9 39.5 103.7 107.7l-.2.2zm-156 68.8c1.3 25.1 28.4 36.8 54.6 35.3 25.6-1.4 54.6-11.4 59.5-73.2-13.2-2.9-27.8-4.4-43.4-4.4-4.8 0-9.6.1-14.4.4-42.9 2.4-57.2 23.2-56.2 41.8z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["content.code.copy", "navigation.expand", "search.highlight", "search.share"], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.50899def.min.js"></script>
      
        <script src="../js/katex.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/auto-render.min.js"></script>
      
    
  </body>
</html>